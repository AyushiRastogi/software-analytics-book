# Bug Prediction

## Motivation
Minimizing the number of bugs in software is an effort central to software engineering - faulty
code fails to fullfill the purpose it was written for, its impact ranges from sligthly
embarrassing to disastrous and dangerous, and last but not least - fixing it 
costs time and money. Resources in a 
software development lifecycle are almost always limited and therefore should be allocated to where
 they are needed most - in order to avoid bugs, they should be focused on the most fault-prone
 areas of the project. Being able to predict where such areas might be would allow more development and 
testing efforts to be allocated on the right places.

However, as noted in @DAmbros2012, reliably predicting which parts of source code are the most 
fault-prone is one of the holy-grails of software engineering. Thus it is not surprising that bug-prediction continues
 to garner a widespread research interest in software analytics, now equipped with the 
 ever-expanding toolbox of data-mining and machine learning techniques. In this survey we 
 investigate the current efforts in bug-prediction in the light of the advances in software analytics methods and focus our attention on answering the
  following research questions:

* **RQ1** What is the current state of the art in bug prediction?
More specifically, we aim to answer the following:
    * What software or other metrics does bug prediction rely on and how good are they?
    * What kind prediction models are predominantly used?
    * How are bug prediction models and results validated and evaluated?
* **RQ2** What is the current state of practice in bug prediction?
    * Are bug prediction techniques applied in practice and if so, how?
    * Are the current developments in the field able to provide actionable tools for developers?
* **RQ3** What are some of the open challenges and directions for future research?


## Research protocol
We started by studying the initial 6 seed papers which were selected based on domain knowledge:

* @Gyimothy2005
* @Catal2009review
* @Arisholm2010
* @DAmbros2010
* @Hall2012
* @Lewis2013

Our searches were based on the following elements:

1. Keyword search using search engines (Scopus, ACM Digital Library, IEEE Explorer).
The search query was constructed so that the paper title had to contain the phrase bug prediction,
 but also the other more general variants used in literature: *bug/defect/fault prediction*. 
The title also had to contain at least one of following keywords: *metrics*, *models*,
 *validation*, *evaluation*, *developers*. To remain within the bug prediction field we required
  *software* to appear in the abstract.

2. Filtering search results by publication date. We excluded papers older than 10 years; that is, published before 2008. 

3. Filtering by the number of citations. We selected papers with 10 or more citations in order to focus on the ones that already have some visibility within the field.

4. Exploring other impactful publications by the same authors.

_Table 1. Papers found by investigating the authors of other papers._

| Starting point    | Type         | Result                                   |
|-------------------|--------------|------------------------------------------|
| @DAmbros2010      | is author of | @DAmbros2012                             |
| @Catal2009review  | is author of | @Catal2011 <br> @Catal2009investigating  |

## Answers

## RQ 1.2: What kind prediction models are predominantly used?
In the section below we will show different models presented by several studies.

### Static predictors
Many older bug-prediction methods [insert refs] use the static code for bug prediction,
these methods argue that complex code is more diffucult to change and 
therefor introduces more bugs.

### Code changes
Predictors based on code changes argue that code changes induce bugs.
And as it turns out, methods based on code modifications clearly outperform
static prediction methods @Moser2008.

#### History Complexity Metric (HCM) @hassan2009
Files that are modified during periods of high change complexity will contain more faults.
Developers changing code during these periods will make mistakes,
because they probably will not be aware of the current state of the code.

Useful in practice because companies may not have a full bug history,
while they probably do have history of code changes.

Outperforms models based on prior faults, 15-38% decrease in prediction errors @hassan2009.
However, @DAmbros2010 contradicts this statement.

### Prior faults
Methods based on prior faults argue that files which in the past contained faults will
probably have more faults in the future.
It is shown that predictors based on previous bugs show better results than 
predictors based on code changes @rahman2011.

#### FixCache @kim2007
Maintains a fixed-size cache of files that are most likely to contain bugs.
Files are added to cache if it meets one of the locality criteria, which are:

* Churn locality: if a file is recently modified it is likely to contain faults
* Temporal locality: if a file contains a fault, it is more likely to contain more faults
* Spatial locality: files that change alongside faulty files are more likely to contain faults

If the cache if full the least recently used file is removed from the cache.
The size of the cache is set at 10% of all files.
Hit rate of about 73-95% at file level, 46-72% at method level.

#### Rahman @rahman2011
The Rahman algorithm is based on the FixCache algorithm,
in their research they found that the temporal locality was by far the most influential factor.
The Rahman algorithm is thus implemented based solely on that factor.

#### Time-weighted risk algorithm @Lewis2013
An algorithm based on the Rahman algorithm,
it includes a weight factor based on how old a commit is, 
older bug fixing commits have less impact on the overall bug-proneness of the file.
Instead of showing top 10% of bug-prone files, this shows the top 20 files.

### Other methods
Besides the more obvious reasonings listed above there are some other possible methods for bug
prediction.

#### Developer centered
@DiNucci2018 proposed a method based on the scattering of changes made by a developer.
These scattering is defined by:

* Structural scattering: based on amount of different components worked on (e.g. packages)
* Semantic scattering: based on the textual difference between classes 
  (i.e. classes which have similar behaviour are textually similar)

Developer experience has no clear correlation with how much faults they introduce @rahman2011.

#### Machine learning
With machine learning methods bugs can be predicted by software tools,
these tools train on the code base, code history and other logs.

Machine learning is also useful for reducing the amount of metrics used for 
bug prediction @shivaji2009.

Downside is that these methods give little insights in why a component is bug-prone @Lewis2013.

Another downside is that this doesn't work for new projects since cross-project
defect prediction does not yet give good results @zimmermann2009.

@Shepperd2014

#### Analysis on Abstract Syntax Trees
Because ASTs give a more high-level description of the syntax of a program
it could give more useful insights for bug-prediction than other analysis methods.

@wang2016 uses ASTs in combination with a machine learning approach for bug prediction.
They also mention that using features from ASTs improves cross-project prediction.

Downside is that ASTs is that dynamic programming languages cannot produce static ASTs.

## RQ 2.1: Are bug prediction techniques applied in practice and if so, how?
No significant effect on developers @Lewis2013.
Managers can use bug-prone list for quality assurance @kim2007.

### Practical problems

* Obvious reasoning @Lewis2013
* Bias towards the new @Lewis2013
* Actionable messages @Lewis2013
* Noise problem @Kim2011
* Granularity: Most methods we found work on a class- or file-based granularity, 
  having a lower level of granularity could improve the usefulness of the prediction for 
  developers @giger2012
* Scalability @Lewis2013

