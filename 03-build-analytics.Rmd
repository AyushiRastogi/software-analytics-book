# Build analytics

## Motivation

### Introduction
Ideally, when building a project from source code to executable, the process should be 
fast and without any errors. Unfortunately, this is not always the case and automated 
builds results notify developers of compile errors, missing dependencies, broken functionality 
and many other problems. This chapter is aimed to give an overview of the effort made in 
build analytics field and Continuous Integration (CI) as an increasingly common development 
practice in many projects. 

### Continuous Integration and Version Control System
Continuous Integration in a term used in software engineering to describe a practice of merging 
all developer working copies to a shared mainline several times a day. CI is in general used 
together with Version Control System (VCS), an application for revision control that ensures 
the management of changes to documents, source code and other collections of information.

<!-- The following paragraph is prone to errors when auto formatting. After a ..^[..] or ..^[..],
there _must_ be a space, else it is interpreted as superscript. --> 

### Build Definition
Build analytics covers research on data extracted from a build process inside a project. This
contains among others, build logs from Continuous Integration such as Travis&nbsp;CI^[See
https://travis-ci.org/], Circle&nbsp;CI^[See https://circleci.com/], Jenkins^[See https://jenkins.io/], 
AppVeyor^[See\ https://www.appveyor.com/] and TeamCity^[See https://www.jetbrains.com/teamcity/] or
surveys among developers about their usage of Continuous Integration or build systems. This
information is often paired with data from Version Control Systems such as Git. 

### Research Questions
We aimed to make a complete overview of build analytics field from analyzing current both
state of the art and state of practice to inspecting the future research that could be done
and finally conclude our survey with the research questions that emerged after this exhaustive
field research. In order to achieve a structural way of summarizing a field, we asked the
following research questions:

**RQ1**: What is the current state of the art in the field of build analytics?

In order to answer to the first research question, we need to present the current topics that
are being explored in the build analytics domain alongside with the research methods, tools 
and datasets acquired for the problems in hand and aggregate and reflect about the main 
research findings that the state-of-the-art papers display.

**RQ2**: What is the current state of practice in the field of build analytics?

This section examines scientific papers to analyse the current trend of build analytics
in the software development industry. We look at the popularity of CI in the industry and 
also explore the increase in the use of Continuous Integration (CI) by discussing its ample benefits.
Furthermore, it will discuss the practices used by engineers in the industry to ensure that 
their code is improving and not decaying. 

**RQ3**: What future research can we expect in the field of build analytics?

In this section we will explore where new challenges lie in the field of build analytics. We will
also show what open research items are described in the papers. This section ends with research
questions based on the open research and challenges in current research.

## Research Protocol {#build-analytics-research-protocol}

### Search Strategy
Taking advantage of the initial seed consisting of Bird and Zimmermann [@bird2017predicting],
Beller et al. [@beller2017oops], Rausch et al. [@rausch2017empirical], Beller et al. TravisTorrent [@beller2017travistorrent],
Pinto et al. [@pinto2018work], Zhao et al. [@zhao2017impact], Widder et al. [@widder2018m] and
Hilton et al. [@hilton2016usage], we used references to find new papers to analyze.
Moreover, we used academical search engine _Google Scholar_ to perform a keyword-based
search for other relevant build analytics domain papers. The keywords used were:
build analytics, machine learning, build time, prediction, continuous integration, build failures,
active learning, build errors, mining, software repositories, open-source software.

### Selection Criteria
In order to provide a valid current overview of build analytics field, we selected only the
relevant papers that were published after 2008, in other words we have not included papers older than
10 years. We had chosen 10 years as our threshold being inspired by "ICSE-Most Influential Paper
10 Years Later" Award. The only paper that does not obey to this rule is cornerstone description
of CI practices written by Martin Fowler, as we considered it important for us to see the practices
evolution in build analytics field. Most of the papers we founded were linked to our research questions
being reference in the sections bellow. From the selected papers, we choose to not include in our
research two papers, as they are case studies on a couple of project and do not introduce new
techniques or applications.

See table \@ref(tab:build-analytics-selected-papers) for an overview of the papers which were
selected for this survey.

## Answers

### Build Analytics State of the Art
**RQ1**: What is the current state of the art in the field of build analytics?

The current state-of-the-art in the build analytics domain refers to the use of machine learning techniques
to increase the productivity when using Continuous Integration (CI), to generate constraints on the 
configuration of the CI that could improve build success rate and to predict build failures even for 
newer projects with less training data available.

The papers identified using the research protocol defined section
\@ref(build-analytics-research-protocol) that give us an overview of the current state of the art
in build analytics field are:

 * HireBuild: an automatic approach to history-driven repair of build scripts [@hassan2018hirebuild] 
 * A tale of CI build failures: An open source and a financial organization perspective [@vassallo2017tale]
 * (No) Influence of Continuous Integration on the Commit Activity in GitHub Projects [@baltes2018no]
 * Built to last or built too fast?: evaluating prediction models for build times [@bisong2017built]
 * Statically Verifying Continuous Integration Configurations [@santolucito2018statically]
 * ACONA: active online model adaptation for predicting continuous integration build failures [@ni2018acona]

The topics that are being explored are:

  * the importance of the build process in a VCS project in reference @hassan2018hirebuild
  * the impact factors of user satisfaction for using a CI tools in reference @widder2018m
  * methods from helping the developer to fix bugs in references @hassan2018hirebuild, @vassallo2018break
  * predicting build time in reference @bisong2017built
  * predicting build failures in references @santolucito2018statically, @ni2018acona

The tools that are being proposed are:

  * BART to help developers fix build errors by generating a summary of the failures
  with useful information, thus eliminating the need to browse error logs  [@vassallo2018break]
  * HireBuild to automatically fix build failures based on previous changes [@hassan2018hirebuild]
  * VeriCI capable of checking the errors in CI configurations files before the developer 
  pushes a commit and without needing to wait for the build result [@santolucito2018statically]
  * ACONA capable of predicting build failure in CI environment for newer projects with less 
  data available [@ni2018acona]

#### Importance of the Build Process

The build process is an important part of a project that uses VCS in the way that based on the findings
of Hassan et al. [@hassan2018hirebuild], 22% of code commits include changes in build script files for either
build working or build fixing purposes. 

#### CI Users Satisfaction

Moreover, recent studies have focused on how satisfied the users of CI tools are, one particular paper 
by Widder et al. [@widder2018m] analyzing what factors have an impact on abandonment of Travis&nbsp;CI. 
This paper finds that increased build complexity reduces the chance of abandonment, but larger projects 
abandon at a higher rate and that a project's language has significant but varying effect. A surprising 
result is that metrics of configuration attempts and knowledge dispersion in the project do not affect 
the rate of abandonment.

#### Patent for Predicting Build Errors

In reference [@bird2017predicting], Bird et al. introduce a method for predicting software build errors. 
This US patent is owned by Microsoft. Having logistic regression as machine learning technique, 
the paper is able to compute the probability of a build to fail. Using this method build errors can be 
better anticipated, which decreases the time between working builds.

#### Predicting Build Time

Another important aspect is the impact of CI on the development process efficiency. One of the
papers that addresses this matters is the one written by Bisong et al. [@bisong2017built]. This paper 
aims to find a balance between the frequency of integration and developer's productivity by proposing 
machine learning models that were able to predict the build taking advantage of the 56 features presented
in TravisTorrent build records. Their models performed quite well with an R-Squared of around 80%, 
meaning that they were able to capture the variation of build time over multiple projects. Their research 
could be useful on one hand for software developers and project managers for a better time management scheme 
and on the other hand for other researchers that may improve their proposed models. 

#### Predicting Build Failures

Moreover, the usage of automation build tools introduces a delay in the development cycle generated by
the waiting time until the build finish successfully. One of the most recent analyzed papers by
Santolucito et al. [@santolucito2018statically] presents a tool VeriCI capable of checking the errors 
in CI configurations files before the developer pushes a commit and without needing to wait for the 
build result. This paper focuses on prediction of build failure without using metadata like number of 
commits, code churn also in the learning process, but relying on the actual user programs and configuration 
scripts. This fact makes the identification of the error cause possible. VeriCI achieves 83% accuracy of 
predicting build failure on real data from GitHub projects and 30-48% of time the error justification provided
by the tool matched the actual error cause. These results seem promising, but there is a need in focusing
more on producing the error justification fact that could make the use of machine learning tools in real
build analytics tools achievable and tolerated.

#### Prediction with Less Data Available

Even if there were considerable efforts in developing powerful and accurate machine learning models
for predicting the outcome of builds, most of this techniques cannot be trained properly without
large project past data. The problem that resulted from this is newer project being unable to take 
advantage of the research conducted before and having to wait until enough data from their project
is generated in order to sufficiently train machine learning models from predicting the build outcome.
In reference @ni2018acona, the most recent paper of this survey which is only published as a poster 
in June 2018, Ni et al. address the problem of build failure prediction in CI environment for newer projects 
with less data available. It is using already trained models from other project with more data available and 
combined them by the means of active learning in order to find which of that models generalized better 
from the problem in hand and to update the models weights accordingly. It is also aimed to cut the expense 
that CI introduce by reducing the label data necessarily for training. Even if the method seems promising, 
the results presented in the poster shows an F-Measure (harmonic average of recall and precision) of around 
40% that could be better improved.

### Build Analytics State of Practice

**RQ2**: What is the current state of practice in the field of build analytics?

Continuous Integration (CI) is a development practice that requires developers to integrate code into a 
share repository several times a day. Each check-in is then verified by an automated build which allows 
engineers to detect any bugs early. 

An overview of Continuous Integration evolution from the introduction of the term to the current practices 
can be seen in the figure bellow:

![CI overview.](figures/build-analytics/state_pr.png)

The papers identified using the research protocol defined in section
\@ref(build-analytics-research-protocol) that give us an overview of the current state of the art
in build analytics domain are:

 * Usage, Costs, and Benefits of Continuous Integration in Open-Source Projects [@hilton2016usage]
 * An Empirical Analysis of Build Failures in the Continuous Integration Workflows of Java-Based Open-Source Software                [@rausch2017empirical]
 * Continuous Integration [@fowler2006continuous]
 * Enabling Agile Testing Through Continuous Integration [@stolberg2009enabling]
 * Travistorrent: Synthesizing Travis Ci and Github for Full-Stack Research on Continuous Integration [@beller2017travistorrent]
 * I’im Leaving You, Travis: A Continuous Integration Breakup Story [@widder2018m]

The topics that are being explored are:

  * Usage of CI in the industry by @hilton2016usage
  * Growing popularity of CI due to the introduction of VCS as suggested by @rausch2017empirical
  * Common practices used in the industry exemplified by @fowler2006continuous
  * Use of common CI practice in the agile approach presented by @stolberg2009enabling
  
The practice that are being proposed are:

  * Maintain a Single Source Repository
  * Automate the Build
  * Make Your Build Self-Testing
  * Everyone Commits To the Mainline Every Day
  * Every Commit Should Build the Mainline on an Integration Machine
  * Fix Broken Builds Immediately
  * Keep the Build Fast
  * Test in a Clone of the Production Environment
  * Make it Easy for Anyone to Get the Latest Executable
  * Everyone can see what's happening
  * Automate Deployment

A survey conduced in open-source projects by Hilton et al. [@hilton2016usage] indicated that 40% of all projects used CI. 
It observed that a median project introduces CI a year into development. Furthermore, the paper claims that 
CI is widely used in practice nowadays. The paper by Rausch et al. [@rausch2017empirical] explores how CI is widely 
available for projects of every size with the introduction of Version Control Systems (VCS) such as GitHub, and hosted 
build automation platforms such as Travis. In this way, CI adoption rates will increase further in the future. 

This is an overview of CI and how it works in daily life. Maintaining this system requires engineers to follow 
fundamental practices presented by Fowler and Foemmel [@fowler2006continuous]. The practices presented 
by Fowler and Foemmel [@fowler2006continuous] are still commonly used today, particularly in the agile 
software industry as suggested by Stolberg [@stolberg2009enabling]. Below is an explanation of each of the practices suggested 
by Fowler and Foemmel [@fowler2006continuous.]

#### Maintain a Single Source Repository

The practice advocates the use of a revision control system for the project’s source code. All artefacts 
required to build the project should be placed in a single repository. This ensures that the system does not
require additional dependencies. It is preferred for changes to be integrated at least once a day. This makes 
it easier to find and remove bugs. The framework is not difficult to implement with the growing popularity of 
Version Control Systems (VCS) such as GitHub, and hosted build automation platforms such as Travis (@beller2017travistorrent).

#### Automate the Build

A single command should have the capability of building the system. A build script should be able to compile code, 
execute unit tests and automate integration. Many build tools are frequently used in continuous integration 
environments. Other functions that the build may include are code quality checks, semantic checks and
measuring technical debt etc. 

#### Make Your Build Self-Testing

Once the code is built, all tests should run to confirm that it behaves as the developer would expect it to behave. 
In this way, we are finding and eradicating software bugs earlier. This saves copious amounts of time in
the integrating phase. 

#### Everyone Commits To the Mainline Every Day

This is one of the most important rules presented by Fowler and Foemmel [@fowler2006continuous]. By committing 
regularly, every developer can reduce the number of conflicting changes. Checking in large data runs thee risk 
of conflicting with other features and can be very challenging to resolve. Committing all changes at least once 
a day is an integral practice of the CI framework. In addition, performing nightly builds in recommended. 

#### Every Commit Should Build the Mainline on an Integration Machine

The system should build commits to the current working version to ensure that they integrate correctly. 
A "nightly build" should also execute at a scheduled time every night. This build should include more 
verification than the ones on other branches. It takes longer to run and is executed less frequently.

#### Fix Broken Builds Immediately

A broken build is anything that prevents the build from reporting success. This could be a compilation error, 
failed test or inspection, problem with the database or failed deployment. In the CI environment, it is 
important that these problems are fixed immediately. 

#### Keep the Build Fast

The build should complete rapidly, so if there is an issue with integration, it can be identified quickly. 
As explored by Widder et al.[ @widder2018m], one of the factors that lead to companies abandoning the CI 
framework is the complexity of the build. A good practice is to have more fast-executing tests than slow tests. 
This means that you need to have more unit tests than other types of tests. 

#### Test in a Clone of the Production Environment

Having a test environment can lead to failures in tested systems when they deploy in the production environment. 
This is because the production environment may differ from the test environment. However, building a replica of 
a production environment is cost effective. Thereby, testing in a clone of the production environment ensures 
that your project is improving and not decaying.  

#### Make it Easy for Anyone to Get the Latest Executable

Builds should be readily available to stakeholders and testers as this can reduce the amount of rework required 
when rebuilding a feature that does not meet requirements. In general, all programmers should start the day by 
updating the project from the repository to ensure everyone is up to date. 

#### Everyone can see what's happening
It should be easy to find out whether the build breaks and what/who made relevant changes. Continuous Integration
is all about communication, so it is important to ensure that everyone can easily see the current state of the
system. This is also another reason why CI works really well in the agile industry [@stolberg2009enabling]. 
Both techniques stress the importance of good communication. 

#### Automate Deployment
It is important to write a script to deploy the application to a live test server that everyone can look at. 
This is an integral aspect of CI as you are moving executables between different environments several times a day.
Automating this process will save time and allow you to deploy the application into any environment easily. 
  
It is important to note that CI does not get rid of bugs, but it does make them dramatically easier
to find and remove. The above practices are important for the smooth functioning of CI framework. These practices
are still relevant today and used by professionals in the industry. 

### Build Analytics Future Research
**RQ3**: What future research can we expect in the field of build analytics?

Currently research on build analytics is limited by some challenges, some are specific to
build analytics and some are applicable to the entire field of software engineering.

The papers identified using the research protocol defined in section
\@ref(build-analytics-research-protocol) that give us an overview of challenges and future research
in the field of build analytics are:

 * Built to last or built too fast?: evaluating prediction models for build times [@bisong2017built]
 * Work Practices and Challenges in Continuous Integration: A Survey with Travis CI Users [@pinto2018work]
 * Statically Verifying Continuous Integration Configurations [@santolucito2018statically]
 * (No) Influence of Continuous Integration on the Commit Activity in GitHub Projects [@baltes2018no]
 * The impact of continuous integration on other software development practices: a large-scale empirical study [@zhao2017impact]
 * Un-Break My Build: Assisting Developers with Build Repair Hints [@vassallo2018break]
 * Oops, my tests broke the build: An explorative analysis of Travis CI with GitHub [@beller2017oops]

In Bisong et al.[@bisong2017built] the main limitation was the performance of the machine learning
algorithm used. In the implementation R was used and it proved not capable of processing the
amounts of data needed. This shows that it is important to choose the right tool when analyzing
data.

In Pinto and Rebouças[@pinto2018work] it is noted that research is often done on open source
software. There are still a lot of possibilities for researching on proprietary software projects.

Tools presented in papers might require a more large scale and long term study to verify that the
tool presented keeps up when it is actually used[@santolucito2018statically].

Future research in build analytics branches in a couple of different topics. Pinto and Rebouças[@pinto2018work]
proposes to focus on getting a better understanding of the users and why they might choose to
abandon an automatic build platform.

Baltes et al.[@baltes2018no] suggest that in future research more perspectives when analyzing commit data should
be taken into account, for instance partitioning commits by developer. It also notes the importance
of more qualitative research.

Some open research questions from recent papers are the following:

  * How do teams change their pull request review practices in response to the introduction of
  continuous integration? [@zhao2017impact]
  * How can we detect if fixing a build configuration requires changes in the remote environment? [@vassallo2018break]
  * Does breaking the build often translate to worse project quality and decreased productivity? [@beller2017oops]

From the synthesis of the works discussed in this section the following research questions emerged:

 * What is the impact of the choice of Continuous Integration platform? Most of the research is done
 on users using Travis&nbsp;CI, there are many other platforms out there. Every platform has their own
 characteristics and this could impact the effectiveness for a specific kind of project.


# Appendix: Build Analytics {-}

Table: (\#tab:build-analytics-selected-papers) Selected papers

| Paper with reference              							              | Source              |  RQ      | Notes |
| ----------------------------------------------- | ------------------- | ------------- | ----- |
| 1. Bird et al. 2017 [@bird2017predicting]           	        | Initial seed        | RQ1      | 1     |         
| 2. Beller et al. 2017 [@beller2017oops]                			  | Initial seed        | RQ3      | -     |                
| 3. Rausch et al. 2017 [@rausch2017empirical]           			  | Initial seed        | RQ2      | -     |
| 4. Beller et al. TravisTorrent 2017 [@beller2017travistorrent]| Initial seed        | RQ2      | -     |
| 5. Pinto et al. 2018 [@pinto2018work]                 			  | Initial seed        | RQ3      | -     |
| 6. Zhao et al. 2017 [@zhao2017impact]                			    | Initial seed        | RQ3      | 2     |
| 7. Widder et al. 2018	[@widder2018m]                   			  | Initial seed        | RQ1      | -     |                   
| 8. Hilton et al. 2016	[@hilton2016usage]               			  | Initial seed        | RQ2      | -     |
| 9. Vassallo et al. 2017 [@vassallo2017tale]              		  | Ref 2               | -        | 3     |
| 11. Hassan and Wang 2018 [@hassan2018hirebuild]          		  | Ref 4               | RQ1      | -     |
| 12. Vassallo et al. 2018 [@vassallo2018break]            		  | Ref 2,3             | RQ1, RQ3 | -     |
| 13. Zampetti et al. 2017 [@zampetti2017open]             		  | Ref by 12           | -        | 3     |
| 14. Baltes et al. 2018 [@baltes2018no]                 			  | GScholar Search     | RQ1, RQ3 | 4     |      
| 15. Bisong et al. 2017 [@bisong2017built]              			  | GScholar Search     | RQ1, RQ3 | 5     |
| 16. Santolucito et al. 2018 [@santolucito2018statically]    	| GScholar Search     | RQ1      | 4     |
| 17. Ni and Li 2018 [@ni2018acona]                  				    | GScholar Search     | RQ1      | 6     |
| 18. Fowler and Foemmel 2006 [@fowler2006continuous]         	| GScholar Search     | RQ2      | 7     |
| 19. Stolberg 2009 [@stolberg2009enabling]         				    | GScholar Search     | RQ2      | 7     |


**Notes**

 1. US patent owned by Microsoft.
 2. Collaboration between universities in China, The Netherlands and The USA.
 3. Not included in this survey as it did not introduce a new technique or practice.
 4. Using search term "Github Continuous Integration".
 5. Using search term "Predicting build time"
 6. Using search term "Predicting build failures"
 7. Using search term "Current practices in Continuous Integration"
 