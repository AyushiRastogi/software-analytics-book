# Build analytics

## Motivation

Ideally, when building a project from source code to executable, the process should be 
fast and without any errors. Unfortunately, this is not always the case and automated 
builds results notify developers of compile errors, missing dependencies, broken functionality 
and many other problems. This chapter is aimed to give an overview of the effort made 
in Build Analytics field and Continuous Integration (CI) as an increasingly common 
development practice in many projects. 

Continuous Integration in a term used in software engineering to describe a practice of merging 
all developer working copies to a shared mainline several times a day. CI is in general used 
together with Version control System (VCS). Version Control System is an application for
revision control that ensures the managment of changes to documents, source code and other
collections of information.

<!-- The following paragraph is prone to errors when auto formatting. After a ..^[..] or ..^[..],
there _must_ be a space, else it is interpreted as superscript. --> 

Build analytics covers research done on data extracted from a build process inside a project. This
contains amongst others, build logs from continuous integration such as Travis&nbsp;CI^[See
https://travis-ci.org/], Circle&nbsp;CI^[See https://circleci.com/], Jenkins^[See https://jenkins.io/], 
AppVeyor^[See\ https://www.appveyor.com/] and TeamCity^[See https://www.jetbrains.com/teamcity/] or
surveys among developers about their usage of Continuous Integration or build systems. This
information is often paired with data from Version Control Systems (VCS) such as Git. 

<!--
 - Define build
 - Define context
 -->
 
In order to get a complete view of the current state of the build analytics field, we ask the
following research questions.

**RQ1**: What is the current state of the art in the field of build analytics?

In order to answer to the first research question, we need to present the current topics that
are being explored in the build analytics domain alogside with the research methods, tools 
and datasets acquired for the problems in hand and aggregate and reflect about the main 
research findings that the state-of-the-art papers display.
<!--
  - Topics that are being explored
  - Research methods, tools and datasets being used
  - Main research findings, aggregated -->

**RQ2**: What is the current state of practice in the field of build analytics?

This section examines scientific papers to analyse the current trend of build analytics
in the software development industry. We look at the popularity of CI in the industry 
as @hilton2016usage describes. In addition, it also explores the increase in the use of 
Continuous Integration (CI) by discussing its ample benefits as @fowler2006continuous presents. 
Furthermore, it will discuss the practices used by engineers in the industry to ensure 
that their code is improving and not decaying. 
<!--
  - Tools and companies creating / employing them
  - Case studies and their findings -->

**RQ3**: What future research can we expect in the field of build analytics?

In this section we will explore where new challenges lie in the field of build analytics. We will
also show what open research items are described in the papers. This section ends with research
questions based on the open research and challenges in current research.

## Research protocol {#build-analytics-research-protocol}

Using the initial seed consisting of @bird2017predicting, @beller2017oops, @rausch2017empirical,
@beller2017travistorrent, @pinto2018work, @zhao2017impact, @widder2018m and @hilton2016usage we
used references to find new papers to analyze. Moreover, we used academical search engines like
_GoogleScholar_ to perform a keyword based search for other relevant build analytics domain papers.
The keywords used were: build analytics, machine learning, build time, prediction, 
continuous integration, build failures, active learning, build errors, mining, 
software repositories, open-source software.

| Paper with reference              | Source              |  RQ      | Notes |
| --------------------------------  | ------------------- | -------- | ----- |                
| 1. @bird2017predicting            | Initial seed        | RQ1      | 1     |         
| 2. @beller2017oops                | Initial seed        | RQ3      |       |                
| 3. @rausch2017empirical           | Initial seed        | RQ2      |       |
| 4. @beller2017travistorrent       | Initial seed        | RQ2      |       |
| 5. @pinto2018work                 | Initial seed        | RQ3      |       |
| 6. @zhao2017impact                | Initial seed        | RQ3      | 2     |
| 7. @widder2018m                   | Initial seed        | RQ1      |       |                   
| 8. @hilton2016usage               | Initial seed        | RQ2      |       |
| 9. @vassallo2017tale              | Ref 2               | -        | 3     |
| 11. @hassan2018hirebuild          | Ref 4               | RQ1      |       |
| 12. @vassallo2018break            | Ref 2,3             | RQ1, RQ3 |       |
| 13. @zampetti2017open             | Ref by 12           | -        | 3     |
| 14. @baltes2018no                 | GScholar Search     | RQ1, RQ3 | 4     |      
| 15. @bisong2017built              | GScholar Search     | RQ1, RQ3 | 5     |
| 16. @santolucito2018statically    | GScholar Search     | RQ1      | 4     |
| 17. @ni2018acona                  | GScholar Search     | RQ1      | 6     |
| 18. @fowler2006continuous         | GScholar Search     | RQ2      | 7     |
| 19. @stolberg2009enabling         | GScholar Search     | RQ2      | 7     |


**Notes**

 1. US patent owned by Microsoft.
 2. Collaboration between universities in China, The Netherlands and The USA.
 3. Not included in this survey as it did not introduce a new technique or practice.
 4. Using search term "Github Continuous Integration".
 5. Using search term "Predicting build time"
 6. Using search term "Predicting build failures"
 7. Using search term "Current practices in Continuous Integration"
 
 Most of the papers we found were linked to our research questions being reference in the sections bellow.
 From the identified papers, we choose to not include in our research two papers: @vassallo2017tale and 
 @zampetti2017open. @vassallo2017tale is a case study of difference in failures on continuous integration 
 between open source software (OSS) and industrial software projects from ING Netherlands and we consider 
 that it does not fit in any of the research question our chapter proposed. @zampetti2017open is again a
 case study of the usage of static analysis tools in 20 Java open source software projects hosted on GitHub 
 that use Travic CI. Taking into account the small generalization degree of the findings highlighted by the
 article, we decide to remove this article from our research as well.

 
## Answers

**RQ1**: What is the current state of the art in the field of build analytics?

The current state-of-the-art in the build analytics domain refers to the use of machine learning techniques
to increase the productivity when using Continuos Integration (CI), to generate constraints on the 
configuration of the CI that could improve build success rate and to predict build failures even for 
newer projects with less training data available.

The papers identified using the research protocol defined in the previous section that give us an
overview of the current state of the art in build analytics field are:

 * @hassan2018hirebuild 
 * @vassallo2017tale
 * @baltes2018no
 * @bisong2017built
 * @santolucito2018statically
 * @ni2018acona


The topics that are being explored are:

  * the importance of the build process in a VCS project @hassan2018hirebuild
  * the impact factors of user satisfaction for using a CI tools @widder2018m
  * methods from helping the developer to fix bugs @hassan2018hirebuild, @vassallo2018break
  * predicting build time @bisong2017built
  * predicting build failures @santolucito2018statically, @ni2018acona

The tools that are being proposed are:

  * BART to help developers fix build errors by generating a summary of the failures
  with useful information, thus eliminating the need to browse error logs @vassallo2018break
  * HireBuild to automatically fix build failures based on previous changes @hassan2018hirebuild
  * VeriCI capable of checking the errors in CI configurations files before the developer 
  pushes a commit and without needing to wait for the build result @santolucito2018statically
  * ACONA capable of predicting build failure in CI environment for newer projects with less 
  data available @ni2018acona


*Importance of the build process* 

The build process is an important part of a project that uses VCS in the way that based on the findings
from @hassan2018hirebuild 22% of code commits include changes in build script files for either
build working or build fixing purposes. 

*CI users satisfaction*

Moreover, recent studies have focused on how satisfied the 
users of CI tools are, one particular paper @widder2018m analyzing what factors have an impact on
abandonment of Travis&nbsp;CI. The paper finds that increased build complexity reduces the chance 
of abandonment, but larger projects abandon at a higher rate and that a project's language has 
significant but varying effect. A surprising result is that metrics of configuration attempts 
and knowledge dispersion in the project do not affect the rate of abandonment.

*Patent for predicting build errors*

@bird2017predicting introduce a method for predicting sofware build errors. This US patent is owned
by Microsoft. Having logistic regression as machine learning technique, the paper is able to compute 
the probability of a build to fail. Using this method build errors can be better anticipated, 
which decreases the time between working builds.


*Predicting build time*

Another important aspect is the impact of CI on the development process efficiency. One of the
papers that adresses this matters is @bisong2017built. This paper aims to find a balance between
the frequency of integration and developer's productivity by proposing machine learning models
that were able to predict the build taking advantage of the 56 features presented in TravisTorrent 
build records. Their models performed quite well with an R-Squared of around 80%, meaning that they
were able to capture the variation of build time over multiple projects. Their research could be 
useful on one hand for software developers and project managers for a better time management scheme 
and on the other hand for other researchers that may improve their proposed models. 

*Predicting build failures*

Moreover, the usage of automation build tools introduces a delay in the development cycle generated by
the waiting time until the build finish successfully. One of the most recent papers analyzed 
@santolucito2018statically presents a tool VeriCI capable of checking the errors in CI configurations 
files before the developer pushes a commit and without needing to wait for the build result. This paper
focuses on prediction of build failure without using metadata like number of commits, code churn also 
in the learning process, but relying on the actual user programs and configuration scripts. This fact 
makes the identification of the error cause possible. VeriCI achieves 83% accuracy of predicting build 
failure on real data from GitHub projects and 30-48% of time the error justification provided by the 
tool matched the actual error cause. These results seem promising, but there is a need in focusing
more on producing the error justification fact that could make the use of machine learning tools in
real build analytics tools achievable and tolerated.

*Prediction with less data available*

Even if there were considerable efforts in developing powerful and accurate machine learning models
for predicting the outcome of builds, most of this techniques cannot be trained properly without
large project past data. The problem that resulted from this is newer project being unable to take 
advantage of the research conducted before and having to wait until enough data from their project
is generated in order to sufficiently train machine learning models from predicting the build outcome.
The most recent paper of this survey which is only published as a poster in June 2018, @ni2018acona,
addresses the problem of build failure prediction in CI environment for newer projects with less 
data available. It is using already trained models from other project with more data available and 
combined them by the means of active learning in order to find which of that models generalized better 
from the problem in hand and to update the models weights accordingly. It is also aimed to cut the expense 
that CI introduce by reducing the label data necessarily for training. Even if the method seems promising, 
the results presented in the poster shows an F-Measure (harmonic average of recall and precision) of around 
40% that could be better improved.


<!--
    - Topics that are being explored
    - Research methods, tools and datasets being used
    - Main research findings, aggregated -->
**RQ2**: What is the current state of practice in the field of build analytics?

Continuous Integration (CI) is a development practise that requires developers to integrate code into a 
share repository several times a day. Each check-in is then verified by an automated build which allows 
engineers to detect any bugs early. 

An overview of Continuous Integration evolution from the introduction of the term to the current practices 
can be seen in the figure bellow:

![CI overview.](figures/build-analytics/state_pr.png)


The papers identified using the research protocol defined in the previous section that give us an
overview of the current state of the art in build analytics domain are:

 * @hilton2016usage
 * @rausch2017empirical
 * @fowler2006continuous
 * @stolberg2009enabling
 * @beller2017travistorrent

 
 The topics that are being explored are:

  * usage of CI in the industry by @hilton2016usage
  * growing popularity of CI due to the introduction of VCS as suggested by @rausch2017empirical
  * common practices used in the industry exemplified by @fowler2006continuous
  * use of common CI practice in the agile approach presented by @stolberg2009enabling
  
The practice that are being proposed are:

  * Maintain a Single Source Repository
  * Automate the Build
  * Make Your Build Self-Testing
  * Everyone Commits To the Mainline Every Day
  * Every Commit Should Build the Mainline on an Integration Machine
  * Fix Broken Builds Immediately
  * Keep the Build Fast
  * Test in a Clone of the Production Environment
  * Make it Easy for Anyone to Get the Latest Executable
  * Everyone can see what's happening
  * Automate Deployment

A survey conduced in open-source projects by @hilton2016usage indicated that 40% of all projects used CI. 
It observed that a median project introduces CI a year into development. Furthermore, the paper claims that 
CI is widely used in practise nowadays. The paper by @rausch2017empirical explores how CI is widely available 
for projects of every size with the introduction of Version Control Systems (VCS) such as GitHub, and hosted 
build automation platforms such as Travis. In this way, CI adoption rates will increase further in the future. 

This is an overview of CI and how it works in daily life. Maintaining this system requires engineers to follow 
fundamental practises presented by @fowler2006continuous. The practises presented by @fowler2006continuous are 
still commonly used today, particularly in the agile software industry as suggested by @stolberg2009enabling.
Below is an explanation of each of the practices suggested by @fowler2006continuous.

*Maintain a Single Source Repository*

The practice advocates the use of a revision control system for the project's source code. All artefacts required 
to build the project should be placed in a single repository. This ensures that the system does not require 
additional dependencies. It is preferred for changes to be integrated at least once a day. This makes it 
easier to find and remove bugs. 

*Automate the Build*

A single command should have the capability of building the system. A build script should be able to compile code, 
execute unit tests and automate integration. Many build tools are frequently used in continuous integration 
environments. Other functions that the build may include are code quality checks, semantic checks and
measuring technical debt etc. 

*Make Your Build Self-Testing*
Once the code is built, all tests should run to confirm that it behaves as the developer would expect it to behave.

*Everyone Commits To the Mainline Every Day*

This is one of the most important rules presented by @fowler2006continuous. By committing regularly, every 
developer can reduce the number of conflicting changes. Checking in large data runs thee risk of conflicting 
with other features and can be very challenging to resolve. Committing all changes at least once a day is an 
integral practice of the CI framework. In addition, performing nightly builds in recommended. 

*Every Commit Should Build the Mainline on an Integration Machine*

The system should build commits to the current working version to ensure that they integrate correctly. 
A "nightly build" should also execute at a scheduled time every night. This build should include more 
verifications than the ones on other branches. It takes longer to run and is executed less frequently.

*Fix Broken Builds Immediately*

A broken build is anything that prevents the build from reporting success. This could be a compilation error, 
failed test or inspection, problem with the database or failed deployment. In the CI environment, it is 
important that these problems are fixed immediately. 

*Keep the Build Fast*

The build should complete rapidly, so if there is an issue with integration, it can be identified quickly. 
A good practice is to have more fast-executing tests than slow tests. This means that you need to have more
unit tests than other types of tests. 

*Test in a Clone of the Production Environment*

Having a test environment can lead to failures in tested systems when they deploy in the production environment. 
This is because the production environment may differ from the test environment. However, building a replica of 
a production environment is cost effective. Thereby, testing in a clone of the production environment ensures 
that your project is improving and not decaying.  

*Make it Easy for Anyone to Get the Latest Executable*

Builds should be readily available to stakeholders and testers as this can reduce the amount of rework required 
when rebuilding a feature that does not meet requirements. In general, all programmers should start the day by 
updating the project from the repository to ensure everyone is up to date. 

*Everyone can see what's happening*
It should be easy to find out whether the build breaks and what/who made relevant changes. 

*Automate Deployment*
It is important to write a script to deploy the application to a live test server that everyone can look at. 

  
It is important to note that CI does not get rid of bugs, but it does make them dramatically easier
to find and remove. The above practises are important for the smooth functioning of CI framework.
  

<!--
    - Tools and companies creating / employing them
    - Case studies and their findings -->

**RQ3**: What future research can we expect in the field of build analytics?

Currently research on build analytics is limited by some challenges, some are specific to
build analytics and some are applicable to the entire field of software engineering.

The papers identified using the research protocol defined in section
\@ref(build-analytics-research-protocol) that give us an overview of challenges and future research
in the field of build analytics are:

 * @bisong2017built
 * @pinto2018work
 * @santolucito2018statically
 * @baltes2018no
 * @zhao2017impact
 * @vassallo2018break
 * @beller2017oops

In @bisong2017built the main limitation was the performance of the machine learning algorithm used.
In the implementation R was used and it proved not capable of processing the amounts of data
needed. This shows that it is important to choose the right tool when analyzing data.

@pinto2018work notes that it's research and many others are done on open source software. There are
still a lot of possibilities for researching on proprietary software projects.

Tools presented in papers might require a more large scale and long term study to verify that the
tool presented keeps up when it is actually used [@santolucito2018statically].

Future research in build analytics branches in a couple of different topics. @pinto2018work
proposes to focus on getting a better understanding of the users and why they might choose to
abandon an automatic build platform.

@baltes2018no suggests that in future research more perspectives when analyzing commit data should
be taken into account, for instance partitioning commits by developer. It also notes the importance
of more qualitative research.

Some open research questions from recent papers are the following:

  * How do teams change their pull request review practices in response to the introduction of
  continuous integration? [@zhao2017impact]
  * How can we detect if fixing a build configuration requires changes in the remote environment? [@vassallo2018break]
  * Does breaking the build often translate to worse project quality and decreased productivity? [@beller2017oops]

From the synthesis of the works discussed in this section the following research questions emerged:

 * What is the impact of the choice of Continuos Integration platform? Most of the research is done
 on users using Travis&nbsp;CI, there are many other platforms out there. Every platform has their own
 characteristics and this could impact the effectiveness for a specific kind of project.
