# Build analytics

## Motivation

Ideally, when building a project from source code to executable, the process should be 
fast and without any errors. Unfortunately, this is not always the case and automated 
builds results notify developers of compile errors, missing dependencies, broken functionality 
and many other problems. This chapter is aimed to give an overview of the effort made 
in Build Analytics field and Continuous Integration (CI) as an increasingly common 
development practice in many projects. 

Continuous Integration in a term used in software engineering to describe a practice of merging 
all developer working copies to a shared mainline several times a day. CI is in general used 
together with Version control System (VCS). Version Control System is an application for
revision control that ensures the managment of changes to documents, source code and other
collections of information.

<!-- The following paragraph is prone to errors when auto formatting. After a ..^[..] or ..^[..],
there _must_ be a space, else it is interpreted as superscript. --> 

Build analytics covers research done on data extracted from a build process inside a project. This
contains amongst others, build logs from continuous integration such as Travis&nbsp;CI^[See
https://travis-ci.org/], Circle&nbsp;CI^[See https://circleci.com/], Jenkins^[See https://jenkins.io/], 
AppVeyor^[See\ https://www.appveyor.com/] and TeamCity^[See https://www.jetbrains.com/teamcity/] or
surveys among developers about their usage of Continuous Integration or build systems. This
information is often paired with data from Version Control Systems (VCS) such as Git. 

<!--
 - Define build
 - Define context
 -->
 
In order to get a complete view of the current state of the build analytics field, we ask the
following research questions.

**RQ1**: What is the current state of the art in the field of build analytics?

In order to answer to the first reseacrh question, we need to present the current topics that
are being explored in the build analytics domain alogside with the research methods, tools 
and datasets acquired for the problems in hand and aggregate and reflect about the main 
research findings that the state-of-the-art papers display.
<!--
  - Topics that are being explored
  - Research methods, tools and datasets being used
  - Main research findings, aggregated -->

**RQ2**: What is the current state of practice in the field of build analytics?

This section examines scientific papers to analyse the current trend of build analytics
in the software development industry. We look at the popularity of CI in the industry 
as @hilton2016usage describes. In addition, it also explores the increase in the use of 
Continuous Integration (CI) by discussing its ample benefits as @fowler2006continuous presents. 
Furthermore, it will discuss the practices used by engineers in the industry to ensure 
that their code is improving and not decaying. 
<!--
  - Tools and companies creating / employing them
  - Case studies and their findings -->

**RQ3**: What future research can we expect in the field of build analytics?

In this section we will explore where new challenges lie in the field of build analytics. We will
also show what open research items are described in the papers. This section ends with research
questions based on the open research and challenges in current research.

## Research protocol

Using the initial seed consisting of @bird2017predicting, @beller2017oops, @rausch2017empirical,
@beller2017travistorrent, @pinto2018work, @zhao2017impact, @widder2018m and @hilton2016usage we
used references to find new papers to analyze. Moreover, we used academical search engines like
_GoogleScholar_ to perform a keyword based search for other relevant build analytics domain papers.
The keywords used were: build analytics, machine learning, build time, prediction, 
continuous integration, build failures, active learning, build errors, mining, 
software repositories, open-source software.

| Paper with reference              | Source              |  RQ      | Notes |
| --------------------------------  | ------------------- | -------- | ----- |                
| 1. @bird2017predicting            | Initial seed        | RQ1      | 1     |         
| 2. @beller2017oops                | Initial seed        | RQ3      |       |                
| 3. @rausch2017empirical           | Initial seed        | RQ2      |       |
| 4. @beller2017travistorrent       | Initial seed        | RQ2      |       |
| 5. @pinto2018work                 | Initial seed        | RQ3      |       |
| 6. @zhao2017impact                | Initial seed        | RQ3      | 2     |
| 7. @widder2018m                   | Initial seed        | RQ1      |       |                   
| 8. @hilton2016usage               | Initial seed        | RQ2      |       |
| 9. @vassallo2017tale              | Ref 2               | -        |       |
| 11. @hassan2018hirebuild          | Ref 4               | RQ1      |       |
| 12. @vassallo2018break            | Ref 2,3             | RQ1, RQ3 |       |
| 13. @zampetti2017open             | Ref by 12           | -        |       |
| 14. @baltes2018no                 | GScholar Search     | RQ1, RQ3 | 3     |      
| 15. @bisong2017built              | GScholar Search     | RQ1, RQ3 | 3     |
| 16. @santolucito2018statically    | GScholar Search     | RQ1      | 3     |
| 17. @ni2018acona                  | GScholar Search     | RQ1      | 3     |
| 18. @fowler2006continuous         | GScholar Search     | RQ2      | 4     |
| 19. @stolberg2009enabling         | GScholar Search     | RQ2      | 4     |




**Notes**

 1. US patent.
 2. Collaboration between universities in China, The Netherlands and The USA.
 3. Using search term "Github Continuous Integration".
 4. Using search term "Current practices in Continuous Integration"


## Answers

**RQ1**: What is the current state of the art in the field of build analytics?

The current state-of-the-art in the build analytics domain refers to the use of machine learning techniques
to increase the productivity when using Continuos Integration (CI), to generate constraints on the 
configuration of the CI that could improve build success rate and to predict build failures even for 
newer projects with less training data available.

The papers identified using the research protocol defined in the previous section that give us an
overview of the current state of the art in build analytics domain are:

 * Hassan et al. 2018 
 * Vassallo et al. 2018
 * Baltes et al. 2018
 * Bisong et al. 2017
 * Santolucito et al. 2018
 * Ni et al. 2018


The topics that are being explored are:

  * the importance of the build process in a VCS project @hassan2018hirebuild
  * the impact factors of user satisfaction for using a CI tools @widder2018m
  * methods from helping the developer to fix bugs @hassan2018hirebuild, @vassallo2018break
  * predicting build time @bisong2017built
  * predicting build failures @santolucito2018statically, @ni2018acona

The tools that are being proposed are:

  * BART to help developers fix build errors by generating a summary of the failures
  with useful information, thus eliminating the need to browse error logs @vassallo2018break
  * HireBuild to automatically fix build failures based on previous changes @hassan2018hirebuild
  * VeriCI capable of checking the errors in CI configurations files before the developer 
  pushes a commit and without needing to wait for the build result @santolucito2018statically
  * ACONA capable of predicting build failure in CI environment for newer projects with less 
  data available @ni2018acona


The build process is an important part of a project that uses VCS in the way that based on the findings
from @hassan2018hirebuild 22% of code commits include changes in build script files for either
build working or build fixing purposes. Moreover, recent studies have focused on how satisfied the 
users of CI tools are, one particular paper @widder2018m analyzing what factors have an impact on
abandonment of Travis&nbsp;CI. The paper finds that increased build complexity reduces the chance 
of abandonment, but larger projects abandon at a higher rate and that a project's language has 
significant but varying effect. A surprising result is that metrics of configuration attempts 
and knowledge dispersion in the project do not affect the rate of abandonment.


Another important aspect is the impact of CI on the development process efficiency. One of the
papers that adresses this matters is @bisong2017built. This paper aims to find a balance between
the frequency of integration and developer's productivity by proposing machine learning models
that were able to predict the build taking advantage of the 56 features presented in TravisTorrent 
build records. Their models performed quite well with an R-Squared of around 80%, meaning that they
were able to capture the variation of build time over multiple projects. Their research could be 
useful on one hand for software developers and project managers for a better time management scheme 
and on the other hand for other researchers that may improve their proposed models. 

Moreover, the usage of automation build tools introduces a delay in the development cycle generated by
the waiting time until the build finish successfully. One of the most recent papers analyzed 
@santolucito2018statically presents a tool VeriCI capable of checking the errors in CI configurations 
files before the developer pushes a commit and without needing to wait for the build result. This paper
focuses on prediction of build failure without using metadata like number of commits, code churn also 
in the learning process, but relying on the actual user programs and configuration scripts. This fact 
makes the identification of the error cause possible. VeriCI achieves 83% accuracy of predicting build 
failure on real data from GitHub projects and 30-48% of time the error justification provided by the 
tool matched the actual error cause. These results seem promising, but there is a need in focusing
more on producing the error justification fact that could make the use of machine learning tools in
real build analytics tools achievable and tolerated.

Even if there were considerable efforts in developing powerful and accurate machine learning models
for predicting the outcome of builds, most of this techniques cannot be trained properly without
large project past data. The problem that resulted from this is newer project being unable to take 
advantage of the research conducted before and having to wait until enough data from their project
is generated in order to sufficiently train machine learning models from predicting the build outcome.
The most recent paper of this survey which is only published as a poster in June 2018, @ni2018acona,
addresses the problem of build failure prediction in CI environment for newer projects with less 
data available. It is using already trained models from other project with more data available and 
combined them by the means of active learning in order to find which of that models generalized better 
from the problem in hand and to update the models weights accordingly. It is also aimed to cut the expense 
that CI introduce by reducing the label data necessarily for training. Even if the method seems promising, 
the results presented in the poster shows an F-Measure (harmonic average of recall and precision) of around 
40% that could be better improved.


<!--
    - Topics that are being explored
    - Research methods, tools and datasets being used
    - Main research findings, aggregated -->
**RQ2**: What is the current state of practice in the field of build analytics?

Continuous Integration is a development practise that requires developers to integrate code into a 
share repository several times a day. Each check-in is then verified by an automated build which allows 
engineers to detect any bugs early. 

An overview over the state of practice in Build Analytics domain can be seen in the figure bellow:

![Build Analytics state of practice overview.](figures/Chapter3/state_pr.png)


The papers identified using the research protocol defined in the previous section that give us an
overview of the current state of the art in build analytics domain are:

 * Hitlon et al. 2016
 * Rausch et al. 2017
 * Fowler et al. 2006
 * Stolberg et al. 2009
 * Beller et al. 2017

 
 The topics that are being explored are:

  * usage of CI in the industry by @hilton2016usage
  * growing popularity of CI due to the introduction of VCS as suggested by @rausch2017empirical
  * common practices used in the industry exemplified by @fowler2006continuous
  * use of common CI practice in the agile approach presented by @stolberg2009enabling
  
The practice that are being proposed are:

  * Maintain a Single Source Repository
  * Automate the Build
  * Make Your Build Self-Testing
  * Everyone Commits To the Mainline Every Day
  * Every Commit Should Build the Mainline on an Integration Machine
  * Fix Broken Builds Immediately
  * Keep the Build Fast
  * Test in a Clone of the Production Environment
  * Make it Easy for Anyone to Get the Latest Executable
  * Everyone can see what's happening
  * Automate Deployment

A survey conduced in open-source projects by @hilton2016usage indicated that 40% of all projects used CI. 
It observed that a median project introduces CI a year into development. Furthermore, the paper claims that 
CI is widely used in practise nowadays. The paper by @rausch2017empirical explores how CI is widely available 
for projects of every size with the introduction of Version Control Systems (VCS) such as GitHub, and hosted 
build automation platforms such as Travis. In this way, CI adoption rates will increase further in the future. 

This is an overview of CI and how it works in daily life. Maintaining this system requires engineers to follow 
fundamental practises presented by @fowler2006continuous. The practises presented by @fowler2006continuous are 
still commonly used today, particularly in the agile software industry as suggested by @stolberg2009enabling.
Below is an explanation of each of the practices suggested by @fowler2006continuous.

*Maintain a Single Source Repository*

The practice advocates the use of a revision control system for the project’s source code. All artefacts required 
to build the project should be placed in a single repository. This ensures that the system does not require 
additional dependencies. It is preferred for changes to be integrated at least once a day. This makes it 
easier to find and remove bugs. 

*Automate the Build*

A single command should have the capability of building the system. A build script should be able to compile code, 
execute unit tests and automate integration. Many build tools are frequently used in continuous integration 
environments. Other functions that the build may include are code quality checks, semantic checks and
measuring technical debt etc. 

*Make Your Build Self-Testing*

Once the code is built, all tests should run to confirm that it behaves as the developer would expect it to behave.

*Everyone Commits To the Mainline Every Day*

This is one of the most important rules presented by @fowler2006continuous. By committing regularly, every 
developer can reduce the number of conflicting changes. Checking in large data runs thee risk of conflicting 
with other features and can be very challenging to resolve. Committing all changes at least once a day is an 
integral practice of the CI framework. In addition, performing nightly builds in recommended. 

*Every Commit Should Build the Mainline on an Integration Machine*

The system should build commits to the current working version to ensure that they integrate correctly. 
A “nightly build” should also execute at a scheduled time every night. This build should include more 
verifications than the ones on other branches. It takes longer to run and is executed less frequently.

*Fix Broken Builds Immediately*
A broken build is anything that prevents the build from reporting success. This could be a compilation error, 
failed test or inspection, problem with the database or failed deployment. In the CI environment, it is 
important that these problems are fixed immediately. 

*Keep the Build Fast*
The build should complete rapidly, so if there is an issue with integration, it can be identified quickly. 
A good practice is to have more fast-executing tests than slow tests. This means that you need to have more
unit tests than other types of tests. 

*Test in a Clone of the Production Environment*

Having a test environment can lead to failures in tested systems when they deploy in the production environment. 
This is because the production environment may differ from the test environment. However, building a replica of 
a production environment is cost effective. Thereby, testing in a clone of the production environment ensures 
that your project is improving and not decaying.  

*Make it Easy for Anyone to Get the Latest Executable*

Builds should be readily available to stakeholders and testers as this can reduce the amount of rework required 
when rebuilding a feature that does not meet requirements. In general, all programmers should start the day by 
updating the project from the repository to ensure everyone is up to date. 

*Everyone can see what's happening*
It should be easy to find out whether the build breaks and what/who made relevant changes. 

*Automate Deployment*
It is important to write a script to deploy the application to a live test server that everyone can look at. 

  
It is important to note that CI does not get rid of bugs, but it does make them dramatically easier
to find and remove. The above practises are important for the smooth functioning of CI framework.
  

<!--
    - Tools and companies creating / employing them
    - Case studies and their findings -->

**RQ3**: What future research can we expect in the field of build analytics?
<!-- List of challenges -->

Currently research on build analytics is limited by some challenges, some are specific to
build analytics and some are applicable to the entire field of software engineering.

In @bisong2017built the main limitation was the performance of the machine learning algorithm used.
In the implementation R was used and it proved not capable of processing the amounts of data
needed. This shows that it is important to choose the right tool when analyzing data.

@pinto2018work notes that it's research and many others are done on open source software. There are
still a lot of possibilities for researching on proprietary software projects.

Tools presented in papers might require a more large scale and long term study to verify that the
tool presented keeps up when it is actually used (@santolucito2018statically).

<!-- An aggregated set of open research items, as described in the papers -->

Future research in build analytics branches in a couple of different topics. @pinto2018work
proposes to focus on getting a better understanding of the users and why they might choose to
abandon an automatic build platform.

@baltes2018no suggests that in future research more perspectives when analyzing commit data should
be taken into account, for instance partitioning commits by developer. It also notes the importance
of more qualitative research.

Some open research questions from recent papers are the following:

  * How do teams change their pull request review practices in response to the introduction of
  continuous integration? (@zhao2017impact)
  * How can we detect if fixing a build configuration requires changes in the remote environment? (@vassallo2018break) 
  * Does breaking the build often translate to worse project quality and decreased productivity? (@beller2017oops)

<!-- Research questions that emerge from the synthesis of the presented works -->

From the synthesis of the works discussed in this section the following research questions emerged:

 * What is the impact of the choice of Continuos Integration platform? Most of the research is done
 on users using Travis&nbsp;CI, there are many other platforms out there. Every platform has their own
 characteristics and this could impact the effectiveness for a specific kind of project.

<!--Commented part to extract info from and add it on the final structure -->


<!-- Below you can find the foundation laid in week 1 & 2, this is to be restructured into answers
to research questions or additional information below research questions. -->

<!--
## Summary of papers

Through this we found the following papers

### @bird2017predicting

_Initial Seed_

This is a US patent grant for a method of predicting software build errors. This patent is owned
by Microsoft. Using logistic regression a prediction can be made on the probability of a build
failing. Using this method build errors can be better anticipated, which decreases the time until
the build works again.

### @beller2017oops

_Initial Seed_

This paper explores data from Travis&nbsp;CI on a large scale by analyzing
2,640,825 build logs of Java and Ruby builds. It uses <span
style="font-variant:small-caps">TravisTorrent</span> as a data source. It is found that the number
one reason for failing builds it test failure. It also explores differences in testing between Java
and Ruby.

### @rausch2017empirical

_Initial Seed_

A stuy on the build results of 14 open source software Java projects. It is similar to
@beller2017oops, albeit on a smaller scale. It does go more in depth on the result and changes
over time.

### @beller2017travistorrent

_Initial Seed_

This paper introduces <span style="font-variant:small-caps">TravisTorrent</span>, a dataset
containing analyzed builds from more than 1,000 projects. This data is freely downloadable from
the internet. It uses <span style="font-variant:small-caps">GHTorrent</span> to link the
information from travis to commits on GitHub.

### @pinto2018work

_Initial Seed_

This paper is a survey amongst Travis&nbsp;CI users. It found that users are not sure whether a job
failure represents a failure or not, that inadequate testing is the most common (technical) reason
for build breakage and that people feel that there is a false sense of confidence when blindly
trusing tests.

### @zhao2017impact

_Initial Seed_

-->

<!-- Note: Interesting collab between Nanjing (China), Eindhoven (Netherlands), UC Davis (USA) and Carnegie Mellon (USA). -->

<!--
This paper analyzed approximately 160,000 projects written in seven different programming
languages. It notes that adoption of CI is often part of a reorganization. It collected
information on the differences before and after adoption of CI. There is also a survey amongst
developers to learn about their experiences in adopting Travis&nbsp;CI.

### @widder2018m

_Initial Seed_

This paper analyzes what factors have impact on abandonment of Travis&nbsp;CI. They find that increased
build complexity reduces the chance of abandonment, but larger projects abandon at a higher rate
and that a project's language has significant but varying effect. A surprising result is that
metrics of configuration attempts and knowledge dispersion in the project do not affect the rate of
abandonment.

### @hilton2016usage

_Initial Seed_

This paper explores which CI system developers use, how developers use CI and why developers use
CI. For this it analyzes data from Github, Travis&nbsp;CI and it conducts a developer survey. It finds
that projects using CI release twice as often, accept pull requests faster and have developers who
are less worried about breaking the build.

### @vassallo2017tale

_References @beller2017oops _

This paper discusses the difference in failures on continuous integration between open source
software (OSS) and industrial software projects. For this 349 Java OSS projects and 418 project
from ING Nederland, a financial organization.

Using cluser analysis it was observed that both kinds of projects share similar build failures,
but in other cases very different patterns emerge.

### @hassan2018hirebuild

_References @beller2017travistorrent _

This paper uses TravisTorrent (@beller2017travistorrent) to show that 22% of code commits include
changes in build script files to keep the build working or to fix the build.

In the paper a tool is proposed to automatically fix build failures based on previous changes.

### @vassallo2018break

_References @beller2017oops, @rausch2017empirical _

This paper proposes a tool called <span style="font-variant:small-caps">BART</span> to help
developers fix build errors. This tool eliminates the need to browse error logs which can be very
long by generating a summary of the failure with useful information.

### @zampetti2017open

_Referenced by @vassallo2018break _

This paper studies the usage of static analysis tools in 20 Java open source software projects
hosted on GitHub and using Travic CI as continuous integration infrastructure. There is
investigated which tools are being used, what types of issues make the build fail or raise
warnings and how is responded to broken builds. 

### @baltes2018no

_Google Scholar search term `Github "Continuous Integration"`, papers from 2018_

This paper analyses 93 GitHub projects before and after adoption of Travis&nbsp;CI. It finds only one
non-negligible effect, an increasing merge ratio, meaning that more merging commits in relation to
all commits after a project started using Travis&nbsp;CI. But the paper also shows that this effect can
be seen on projects not adopting CI. It shows the importance of having a proper dataset with as
little bias as possible.

## What is the current state of the art in the field of build analytics?

The current state-of-the-art in build analytics domain refers to the use of machine learning techniques
to increase the productivity when using Continuos Integration (CI), to generate contraints on the 
configuration of the CI that could improve build success rate and to predict build failures even for 
newer projects with less training data available. Beside the papers from the initial seed, we will discuss
the following state-of-the-art aproaches papers:

### @bisong2017built
This paper aims to find a balance between the frequency of integration and developers productivity. 
They proposed models able to predict the build time of a job taking advantage of data from TravisTorrent. 
Their research is also slighty addressing the problem of optimal build time. Their method consists of 
selecting using different strategies to select the relevant features from the 56 features presented in 
TravisTorrent build records and applying a set of both linear and non-linear algorithm for predicting 
the time of a build. They evaluate the models performance using Root Mean Square Error (RMSE) and R-Squared 
and obtained for some models like Extreme-Gradient-Boosting(XGBOOST) a very high R-Squared around 80%, which 
shows that their model was able to capture the variation of build time over multiple projects. The main downfall 
of this paper is the testing size of only 10000 records of the 1,846,396 available data due to computational 
limits resulted probably from the usage of R machine learning packages, instead of python with TensorFlow. 
Their research could be useful on one hand for software developers and project managers for a better time 
management scheme and one the other hand for other researchers that may improve their proposed models. 




### @santolucito2018statically
The paper presents a tool VeriCI capable of checking the errors in CI configurations files before the 
developer push a commit and without needing to wait for the build result. Even if there are some other 
papers that achieve even higher accuracy in prediction of build failures, this paper is unique by not 
using metadata in the learning process like number of commits, code churn and so on. The authors rely 
on the actual user programs and configuration scripts, fact that make the identification of the error 
cause possible. Their approach consists of the following steps: give a formal description to the CI build 
process, extract the right code features and train self-explainable decision trees. VeriCI achieve 
83% accuracy of predicting build failure on real data from GitHub projects and 30-48% of time the error 
justification provided by the tool matched the actual error cause. Even if VeriCI is capable of locate 
and give a reason for the expected failure, the false positive rate is quite high, therefore the authors
proposed as a future work the analysis of the cost impact that a high rate of false positive has and 
also deploying the tool in large scale of CI enviroments.


### @ni2018acona
This paper is posted only as a cover so far. It is the most recent paper of this survey, with the poster 
being published in June 2018. The paper addresses the problem of build failure prediction in CI environment 
for newer projects with less data available. It is using already trained models from other project with more 
data available and combined them by the means of active learning in order to find which of that models 
generalized better from the problem in hand and to update the models weights accordingly. It is also aimed 
to cut the expense that CI introduce by reducing the label data necessarily for training. Even if the method 
seems promising, the results presented in the poster shows an F-Measure (harmonic average of recall and precision) 
of around 40% that could be better improved.


## What is the current state of practice in the field of build analytics?

IBM’s Grady Booch first proposed the methodology of Continuous Integration in the 1990s. 
It became widely used when adopted by Extreme Programming in the 1996. 
In 2000,  @fowler2006continuous wrote the cornerstone description of integration practises. 
The following section provides critical analysis of the papers presented and explains the 
current practises of build analytics in our industry. 

### @fowler2006continuous

In this paper, Martin talks about the current state of the software industry in terms of Continuous
Integration (CI) and comments on the practises required to implement CI effectively. He talks about
his experience working for a large English electronics company where the development of a project
took two years and the integration process took several months. Integration is a long and
unpredictable process. Martin suggested this approach and that the two most common reactions he got
were: “it can’t work (here)” or “doing it won’t make much difference”.  He expresses that most
engineers don’t know how simple the process can be of setting the CI framework up. In this way, we
get a glimpse into the practises popular within the industry regarding build analytics.

### @hilton2016usage

This paper examines the usage, costs and benefits of Continuous Integration. A survey conducted in
open-source projects indicated that 40% of all projects used CI. Of the projects that used CI, 90%
used Travis&nbsp;CI for their CI services. They also determine that the more popular projects use CI but
there is no correlation between the popularity of language and usage of CI. It also observes that
the median project introduces CI a year into development. The paper claims that CI is widely used
in practise nowadays and CI adoption rates will increase even further in the future. 

### @rausch2017empirical

Version Control Systems such as GitHub, and hosted build automation platforms such as Travis&nbsp;CI,
have made Continuous Integration is widely available for projects of every size. This paper
suggests that CI is widely used and has improved the quality of processes and developed software
itself. However, the article suggests that there is little known about the variety and frequency of
errors that cause builds to fail. It suggests that developers should eliminate flaky tests and
address common issues regularly to keep the build system healthy.

### @stolberg2009enabling

This paper defines CI as a key element in agile software development and testing environment. It
also uses Marin Fowler’s practises of CI (as discussed previously) and expresses the importance of
CI in the software industry.  
-->
